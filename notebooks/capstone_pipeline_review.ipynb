{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2d0d819",
   "metadata": {},
   "source": [
    "# 0. Reproducibility and Environment\n",
    "\n",
    "This notebook implements a modular aspect-based sentiment analysis pipeline using coordinated small language model (SLM) agents. The pipeline performs the following steps:\n",
    "\n",
    "1. Load and chunk Amazon Electronics product reviews.\n",
    "2. Extract product aspects (e.g., \"battery life\", \"fan noise\", \"delivery speed\") using a small hosted model (feature-finder agent).\n",
    "3. Score sentiment for each extracted aspect using a second small hosted model (sentiment-scorer agent).\n",
    "4. Aggregate results, compute quality metrics (MAE, rank correlation with user star ratings), measure latency, and estimate per-review cost.\n",
    "\n",
    "All API calls are made to private Hugging Face Inference Endpoints. Secrets (tokens, endpoint URLs) are NOT stored in this notebook. They are loaded at runtime from a local `.env` file.\n",
    "\n",
    "To reproduce:\n",
    "- Create and activate a virtual environment.\n",
    "- `pip install -r requirements.txt`\n",
    "- Create a `.env` file in the project root with:\n",
    "  - HF_TOKEN\n",
    "  - HF_ENDPOINT_URL             (feature finder endpoint)\n",
    "  - SENTIMENT_ENDPOINT_URL      (sentiment scorer endpoint, OpenAI-style /v1/chat/completions)\n",
    "  - SENTIMENT_MODEL_NAME        (model ID string for logging)\n",
    "- Then run this notebook top to bottom.\n",
    "\n",
    "All intermediate artifacts (chunks, extracted aspects, sentiment scores, latency logs, cost tables, and final plots) are written to `datasets/` and `outputs/` for auditability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048dcc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env check:\n",
      "  HF_TOKEN present:          True\n",
      "  FEATURE_FINDER_ENDPOINT?:  True\n",
      "  SENTIMENT_ENDPOINT_URL?:   True\n",
      "  SENTIMENT_MODEL_NAME:      Qwen/Qwen2.5-3B-Instruct\n",
      "\n",
      "Path check:\n",
      "  REPO_ROOT       = c:\\Users\\senth\\Downloads\\slm_absa_capstone\n",
      "  DATASETS_DIR    = c:\\Users\\senth\\Downloads\\slm_absa_capstone\\datasets\n",
      "  OUTPUTS_DIR     = c:\\Users\\senth\\Downloads\\slm_absa_capstone\\notebooks\\outputs\n",
      "  RAW_DIR         = c:\\Users\\senth\\Downloads\\slm_absa_capstone\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------\n",
    "# Load environment\n",
    "# -----------------\n",
    "load_dotenv()  # this will read .env from the working directory or any parent dir\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "FEATURE_FINDER_ENDPOINT_URL = os.getenv(\"HF_ENDPOINT_URL\")            # Phi-3 mini endpoint (feature finder)\n",
    "SENTIMENT_ENDPOINT_URL      = os.getenv(\"SENTIMENT_ENDPOINT_URL\")     # Qwen endpoint (/v1/chat/completions path)\n",
    "SENTIMENT_MODEL_NAME        = os.getenv(\"SENTIMENT_MODEL_NAME\")       # for logging/plots only\n",
    "\n",
    "# basic safety assertions so the notebook fails fast if env isn't set\n",
    "assert HF_TOKEN is not None, \"HF_TOKEN not found in environment (.env missing or variable unset)\"\n",
    "assert FEATURE_FINDER_ENDPOINT_URL is not None, \"HF_ENDPOINT_URL not found in environment\"\n",
    "assert SENTIMENT_ENDPOINT_URL is not None, \"SENTIMENT_ENDPOINT_URL not found in environment\"\n",
    "assert SENTIMENT_MODEL_NAME is not None, \"SENTIMENT_MODEL_NAME not found in environment\"\n",
    "\n",
    "# -----------------\n",
    "# Project paths\n",
    "# -----------------\n",
    "\n",
    "REPO_ROOT = Path.cwd()\n",
    "if REPO_ROOT.name.lower() == \"notebooks\":\n",
    "    REPO_ROOT = REPO_ROOT.parent\n",
    "\n",
    "DATASETS_DIR = REPO_ROOT / \"datasets\"\n",
    "OUTPUTS_DIR  = REPO_ROOT / \"notebooks\" / \"outputs\"  \n",
    "RAW_DIR      = REPO_ROOT / \"data\" / \"raw\"\n",
    "\n",
    "print(\"Env check:\")\n",
    "print(\"  HF_TOKEN present:         \", HF_TOKEN is not None)\n",
    "print(\"  FEATURE_FINDER_ENDPOINT?: \", FEATURE_FINDER_ENDPOINT_URL is not None)\n",
    "print(\"  SENTIMENT_ENDPOINT_URL?:  \", SENTIMENT_ENDPOINT_URL is not None)\n",
    "print(\"  SENTIMENT_MODEL_NAME:     \", SENTIMENT_MODEL_NAME)\n",
    "\n",
    "print(\"\\nPath check:\")\n",
    "print(\"  REPO_ROOT       =\", REPO_ROOT)\n",
    "print(\"  DATASETS_DIR    =\", DATASETS_DIR)\n",
    "print(\"  OUTPUTS_DIR     =\", OUTPUTS_DIR)\n",
    "print(\"  RAW_DIR         =\", RAW_DIR)\n",
    "\n",
    "# helper: make sure dirs exist (no-op if already there)\n",
    "DATASETS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(RAW_DIR).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6b5955",
   "metadata": {},
   "source": [
    "## 1. Data ingestion and chunking\n",
    "\n",
    "This section loads a subset of Amazon Electronics product reviews and prepares them for downstream modeling.\n",
    "\n",
    "**Input**\n",
    "- Raw source: `data/raw/reviews_Electronics_5.json.gz` (public Amazon review dump in JSONL.gz format)\n",
    "  - Each line is a single review with fields such as `reviewerID`, `asin`, `reviewText`, `overall`, and `reviewTime`.\n",
    "- Only a 200-row sample is used in this study for computational cost control.\n",
    "\n",
    "**Processing**\n",
    "1. Read the raw gzip file and convert it to a pandas DataFrame.\n",
    "2. Sample 200 reviews deterministically.\n",
    "3. Normalize columns into:\n",
    "   - `review_id` (string id for each review),\n",
    "   - `asin` (product id),\n",
    "   - `reviewText` (full free-text review),\n",
    "   - `overall` (star rating 1–5),\n",
    "   - `helpful`, `summary`, `reviewTime`, `category`.\n",
    "4. Chunk each `reviewText` into spans of ≤700 characters.\n",
    "   - Long reviews become multiple chunks.\n",
    "   - Each chunk gets its own `chunk_id` like `<review_id>-0`, `<review_id>-1`, etc.\n",
    "\n",
    "**Outputs (saved to disk)**\n",
    "- `datasets/electronics_sample.csv`  \n",
    "  One row per review (200 rows).\n",
    "- `datasets/electronics_chunks.csv`  \n",
    "  One row per chunk (291 rows in this run).\n",
    "\n",
    "These artifacts are then fed to the feature extraction agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8869b10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using source file: c:\\Users\\senth\\Downloads\\slm_absa_capstone\\data\\raw\\reviews_Electronics_5.json.gz\n",
      "Total rows in raw dump: 1689188\n",
      "Sample columns: ['review_id', 'asin', 'reviewText', 'overall', 'helpful', 'summary', 'reviewTime', 'category']\n",
      "Sample shape: (200, 8)\n",
      "            review_id        asin  overall  \\\n",
      "0  ELECTRONICS_000000  0528881469      5.0   \n",
      "1  ELECTRONICS_000001  0528881469      1.0   \n",
      "2  ELECTRONICS_000002  0528881469      3.0   \n",
      "3  ELECTRONICS_000003  0528881469      2.0   \n",
      "4  ELECTRONICS_000004  0528881469      1.0   \n",
      "\n",
      "                                  summary  \\\n",
      "0                         Gotta have GPS!   \n",
      "1                       Very Disappointed   \n",
      "2                          1st impression   \n",
      "3                 Great grafics, POOR GPS   \n",
      "4  Major issues, only excuses for support   \n",
      "\n",
      "                                          reviewText  \n",
      "0  We got this GPS for my husband who is an (OTR)...  \n",
      "1  I'm a professional OTR truck driver, and I bou...  \n",
      "2  Well, what can I say.  I've had this unit in m...  \n",
      "3  Not going to write a long review, even thought...  \n",
      "4  I've had mine for a year and here's what we go...  \n",
      "num reviews: 200 | num chunks: 241\n",
      "avg chars per chunk: 321.97\n",
      "max chars per chunk: 700\n",
      "\n",
      "Saved:\n",
      "  c:\\Users\\senth\\Downloads\\slm_absa_capstone\\datasets\\electronics_sample.csv\n",
      "  c:\\Users\\senth\\Downloads\\slm_absa_capstone\\datasets\\electronics_chunks.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>helpful</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ELECTRONICS_000000</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Gotta have GPS!</td>\n",
       "      <td>06 2, 2013</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ELECTRONICS_000001</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[12, 15]</td>\n",
       "      <td>Very Disappointed</td>\n",
       "      <td>11 25, 2010</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELECTRONICS_000002</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[43, 45]</td>\n",
       "      <td>1st impression</td>\n",
       "      <td>09 9, 2010</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            review_id        asin  \\\n",
       "0  ELECTRONICS_000000  0528881469   \n",
       "1  ELECTRONICS_000001  0528881469   \n",
       "2  ELECTRONICS_000002  0528881469   \n",
       "\n",
       "                                          reviewText  overall   helpful  \\\n",
       "0  We got this GPS for my husband who is an (OTR)...      5.0    [0, 0]   \n",
       "1  I'm a professional OTR truck driver, and I bou...      1.0  [12, 15]   \n",
       "2  Well, what can I say.  I've had this unit in m...      3.0  [43, 45]   \n",
       "\n",
       "             summary   reviewTime     category  \n",
       "0    Gotta have GPS!   06 2, 2013  Electronics  \n",
       "1  Very Disappointed  11 25, 2010  Electronics  \n",
       "2     1st impression   09 9, 2010  Electronics  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>span_start</th>\n",
       "      <th>span_end</th>\n",
       "      <th>asin</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ELECTRONICS_000000</td>\n",
       "      <td>ELECTRONICS_000000-0</td>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ELECTRONICS_000000</td>\n",
       "      <td>ELECTRONICS_000000-1</td>\n",
       "      <td>of my email I received a email back with instr...</td>\n",
       "      <td>700</td>\n",
       "      <td>805</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELECTRONICS_000001</td>\n",
       "      <td>ELECTRONICS_000001-0</td>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            review_id              chunk_id  \\\n",
       "0  ELECTRONICS_000000  ELECTRONICS_000000-0   \n",
       "1  ELECTRONICS_000000  ELECTRONICS_000000-1   \n",
       "2  ELECTRONICS_000001  ELECTRONICS_000001-0   \n",
       "\n",
       "                                          chunk_text  span_start  span_end  \\\n",
       "0  We got this GPS for my husband who is an (OTR)...           0       700   \n",
       "1  of my email I received a email back with instr...         700       805   \n",
       "2  I'm a professional OTR truck driver, and I bou...           0       700   \n",
       "\n",
       "         asin     category  \n",
       "0  0528881469  Electronics  \n",
       "1  0528881469  Electronics  \n",
       "2  0528881469  Electronics  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------\n",
    "# Helper: read raw Amazon dump\n",
    "# ------------------------\n",
    "def load_amazon_electronics_raw(raw_path: Path, max_rows: int = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    raw_path: path to reviews_Electronics_5.json.gz\n",
    "    Returns a DataFrame with at least:\n",
    "      reviewerID, asin, reviewText, overall, helpful, summary, reviewTime\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    with gzip.open(raw_path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "            rows.append(obj)\n",
    "            if max_rows is not None and len(rows) >= max_rows:\n",
    "                break\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# 1. Load raw data\n",
    "# ------------------------\n",
    "raw_gz_candidate_paths = [\n",
    "    RAW_DIR / \"reviews_Electronics_5.json.gz\",\n",
    "    REPO_ROOT / \"data\" / \"raw\" / \"reviews_Electronics_5.json.gz\",\n",
    "    REPO_ROOT / \"reviews_Electronics_5.json.gz\",\n",
    "]\n",
    "\n",
    "raw_path = None\n",
    "for p in raw_gz_candidate_paths:\n",
    "    if p.exists():\n",
    "        raw_path = p\n",
    "        break\n",
    "\n",
    "if raw_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find reviews_Electronics_5.json.gz in expected locations.\\n\"\n",
    "        f\"Tried: {raw_gz_candidate_paths}\"\n",
    "    )\n",
    "\n",
    "print(\"Using source file:\", raw_path)\n",
    "\n",
    "df_raw_full = load_amazon_electronics_raw(raw_path)\n",
    "print(\"Total rows in raw dump:\", len(df_raw_full))\n",
    "\n",
    "# ------------------------\n",
    "# 2. Take deterministic 200-row slice\n",
    "# ------------------------\n",
    "sample_df = (\n",
    "    df_raw_full\n",
    "    .head(200)  # deterministic sample: first 200 rows\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# add category column for consistency with earlier steps\n",
    "sample_df[\"category\"] = \"Electronics\"\n",
    "\n",
    "# create stable review_id like ELECTRONICS_<row_index>\n",
    "sample_df[\"review_id\"] = [\n",
    "    f\"ELECTRONICS_{i:06d}\" for i in range(len(sample_df))\n",
    "]\n",
    "\n",
    "# reorder/rename columns exactly as used downstream\n",
    "sample_df = sample_df.rename(\n",
    "    columns={\n",
    "        \"reviewText\": \"reviewText\",\n",
    "        \"overall\": \"overall\",\n",
    "        \"asin\": \"asin\",\n",
    "        \"helpful\": \"helpful\",\n",
    "        \"summary\": \"summary\",\n",
    "        \"reviewTime\": \"reviewTime\",\n",
    "    }\n",
    ")[[\"review_id\", \"asin\", \"reviewText\", \"overall\", \"helpful\",\n",
    "   \"summary\", \"reviewTime\", \"category\"]]\n",
    "\n",
    "print(\"Sample columns:\", list(sample_df.columns))\n",
    "print(\"Sample shape:\", sample_df.shape)\n",
    "print(sample_df.head(5)[[\"review_id\",\"asin\",\"overall\",\"summary\",\"reviewText\"]])\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# 3. Chunking function\n",
    "# ------------------------\n",
    "def chunk_review_text(review_id: str,\n",
    "                       text: str,\n",
    "                       max_chars: int = 700) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Split long review text into <=max_chars character spans.\n",
    "    Returns list of dicts with:\n",
    "      review_id, chunk_id, chunk_text, span_start, span_end\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    idx = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + max_chars, len(text))\n",
    "        chunk_text = text[start:end]\n",
    "        chunk_id = f\"{review_id}-{idx}\"\n",
    "        chunks.append({\n",
    "            \"review_id\": review_id,\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"chunk_text\": chunk_text,\n",
    "            \"span_start\": start,\n",
    "            \"span_end\": end,\n",
    "        })\n",
    "        start = end\n",
    "        idx += 1\n",
    "    if len(text) == 0:\n",
    "        # still emit a single empty chunk\n",
    "        chunk_id = f\"{review_id}-0\"\n",
    "        chunks.append({\n",
    "            \"review_id\": review_id,\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"chunk_text\": \"\",\n",
    "            \"span_start\": 0,\n",
    "            \"span_end\": 0,\n",
    "        })\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# apply chunking to all 200 reviews\n",
    "all_chunk_rows = []\n",
    "for _, row in sample_df.iterrows():\n",
    "    chs = chunk_review_text(\n",
    "        review_id=row[\"review_id\"],\n",
    "        text=str(row[\"reviewText\"]) if not pd.isna(row[\"reviewText\"]) else \"\",\n",
    "        max_chars=700\n",
    "    )\n",
    "    for ch in chs:\n",
    "        ch[\"asin\"] = row[\"asin\"]\n",
    "        ch[\"category\"] = row[\"category\"]\n",
    "    all_chunk_rows.extend(chs)\n",
    "\n",
    "chunks_df = pd.DataFrame(all_chunk_rows)\n",
    "\n",
    "print(\"num reviews:\", sample_df.shape[0],\n",
    "      \"| num chunks:\", chunks_df.shape[0])\n",
    "\n",
    "avg_chars = chunks_df[\"chunk_text\"].str.len().mean()\n",
    "max_chars = chunks_df[\"chunk_text\"].str.len().max()\n",
    "print(\"avg chars per chunk:\", round(avg_chars,2))\n",
    "print(\"max chars per chunk:\", max_chars)\n",
    "\n",
    "# light sanity checks\n",
    "assert chunks_df[\"chunk_id\"].is_unique, \"chunk_id should be unique\"\n",
    "assert chunks_df[\"review_id\"].nunique() == sample_df[\"review_id\"].nunique()\n",
    "\n",
    "# ------------------------\n",
    "# 4. Save artifacts\n",
    "# ------------------------\n",
    "sample_out_path = DATASETS_DIR / \"electronics_sample.csv\"\n",
    "chunks_out_path = DATASETS_DIR / \"electronics_chunks.csv\"\n",
    "\n",
    "sample_df.to_csv(sample_out_path, index=False)\n",
    "chunks_df.to_csv(chunks_out_path, index=False)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" \", sample_out_path)\n",
    "print(\" \", chunks_out_path)\n",
    "\n",
    "display(sample_df.head(3))\n",
    "display(chunks_df.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd774249",
   "metadata": {},
   "source": [
    "## 2. Aspect extraction (Feature-Finder agent)\n",
    "\n",
    "Goal: Identify which concrete product attributes are being discussed in each review chunk.\n",
    "\n",
    "For example, from:\n",
    "> \"The battery lasts two days, but the speaker is weak.\"\n",
    "\n",
    "the agent should return aspects like:\n",
    "- \"battery life\"\n",
    "- \"speaker quality\"\n",
    "\n",
    "not generic sentiment words like \"good\" or \"bad\".\n",
    "\n",
    "### Approach\n",
    "- Each 700-character chunk from Section 1 is sent to a small language model (SLM) hosted on a rented GPU endpoint.\n",
    "- The model is prompted to extract product-specific aspects and return **machine-readable JSON** of the form:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"features\": [\n",
    "    { \"name\": \"<aspect phrase>\", \"span\": [start_char, end_char] },\n",
    "    ...\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72b45044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-Finder URL being used: https://u39a2sabvf8790g2.us-east-1.aws.endpoints.huggingface.cloud/v1/chat/completions\n",
      "Loaded chunks: 241\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>span_start</th>\n",
       "      <th>span_end</th>\n",
       "      <th>asin</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ELECTRONICS_000000</td>\n",
       "      <td>ELECTRONICS_000000-0</td>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>528881469</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ELECTRONICS_000000</td>\n",
       "      <td>ELECTRONICS_000000-1</td>\n",
       "      <td>of my email I received a email back with instr...</td>\n",
       "      <td>700</td>\n",
       "      <td>805</td>\n",
       "      <td>528881469</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELECTRONICS_000001</td>\n",
       "      <td>ELECTRONICS_000001-0</td>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>528881469</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ELECTRONICS_000001</td>\n",
       "      <td>ELECTRONICS_000001-1</td>\n",
       "      <td>sold.  I ran the update program multiple times...</td>\n",
       "      <td>700</td>\n",
       "      <td>1400</td>\n",
       "      <td>528881469</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ELECTRONICS_000001</td>\n",
       "      <td>ELECTRONICS_000001-2</td>\n",
       "      <td>tes to figure a re-route, and it happened mult...</td>\n",
       "      <td>1400</td>\n",
       "      <td>2100</td>\n",
       "      <td>528881469</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            review_id              chunk_id  \\\n",
       "0  ELECTRONICS_000000  ELECTRONICS_000000-0   \n",
       "1  ELECTRONICS_000000  ELECTRONICS_000000-1   \n",
       "2  ELECTRONICS_000001  ELECTRONICS_000001-0   \n",
       "3  ELECTRONICS_000001  ELECTRONICS_000001-1   \n",
       "4  ELECTRONICS_000001  ELECTRONICS_000001-2   \n",
       "\n",
       "                                          chunk_text  span_start  span_end  \\\n",
       "0  We got this GPS for my husband who is an (OTR)...           0       700   \n",
       "1  of my email I received a email back with instr...         700       805   \n",
       "2  I'm a professional OTR truck driver, and I bou...           0       700   \n",
       "3  sold.  I ran the update program multiple times...         700      1400   \n",
       "4  tes to figure a re-route, and it happened mult...        1400      2100   \n",
       "\n",
       "        asin     category  \n",
       "0  528881469  Electronics  \n",
       "1  528881469  Electronics  \n",
       "2  528881469  Electronics  \n",
       "3  528881469  Electronics  \n",
       "4  528881469  Electronics  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 25/241 chunks\n",
      "Processed 50/241 chunks\n",
      "Processed 75/241 chunks\n",
      "Processed 100/241 chunks\n",
      "Processed 125/241 chunks\n",
      "Processed 150/241 chunks\n",
      "Processed 175/241 chunks\n",
      "Processed 200/241 chunks\n",
      "Processed 225/241 chunks\n",
      "\n",
      "First model response sample:\n",
      "\n",
      "{\n",
      "  \"chunk_id\": \"ELECTRONICS_000000-0\",\n",
      "  \"review_id\": \"ELECTRONICS_000000\",\n",
      "  \"features\": [],\n",
      "  \"logs\": {\n",
      "    \"latency_ms\": 2280.43532371521,\n",
      "    \"status\": \"http_error_503\",\n",
      "    \"usage\": null\n",
      "  },\n",
      "  \"raw_assistant_text\": null\n",
      "}\n",
      "\n",
      "Saved:\n",
      "  c:\\Users\\senth\\Downloads\\slm_absa_capstone\\notebooks\\outputs\\feature_finder_raw_large.jsonl\n",
      "  c:\\Users\\senth\\Downloads\\slm_absa_capstone\\notebooks\\outputs\\feature_finder_raw_large_debug.txt\n",
      "\n",
      "Saved review-level summary -> c:\\Users\\senth\\Downloads\\slm_absa_capstone\\notebooks\\outputs\\feature_finder_by_review_large.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\senth\\AppData\\Local\\Temp\\ipykernel_22188\\2149346863.py:319: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(agg_review)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>n_chunks</th>\n",
       "      <th>features_union</th>\n",
       "      <th>n_unique_aspects</th>\n",
       "      <th>latency_ms_total</th>\n",
       "      <th>latency_ms_avg</th>\n",
       "      <th>num_ok</th>\n",
       "      <th>num_not_ok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ELECTRONICS_000000</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3153.794050</td>\n",
       "      <td>1576.897025</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ELECTRONICS_000001</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3161.010742</td>\n",
       "      <td>790.252686</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELECTRONICS_000002</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>5577.016830</td>\n",
       "      <td>796.716690</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ELECTRONICS_000003</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4251.026869</td>\n",
       "      <td>1062.756717</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ELECTRONICS_000004</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1760.791779</td>\n",
       "      <td>880.395889</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ELECTRONICS_000005</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>850.936413</td>\n",
       "      <td>850.936413</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ELECTRONICS_000006</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>665.442467</td>\n",
       "      <td>665.442467</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ELECTRONICS_000007</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>843.623877</td>\n",
       "      <td>843.623877</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ELECTRONICS_000008</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>817.167759</td>\n",
       "      <td>817.167759</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ELECTRONICS_000009</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1623.966217</td>\n",
       "      <td>811.983109</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            review_id  n_chunks features_union  n_unique_aspects  \\\n",
       "0  ELECTRONICS_000000         2                                0   \n",
       "1  ELECTRONICS_000001         4                                0   \n",
       "2  ELECTRONICS_000002         7                                0   \n",
       "3  ELECTRONICS_000003         4                                0   \n",
       "4  ELECTRONICS_000004         2                                0   \n",
       "5  ELECTRONICS_000005         1                                0   \n",
       "6  ELECTRONICS_000006         1                                0   \n",
       "7  ELECTRONICS_000007         1                                0   \n",
       "8  ELECTRONICS_000008         1                                0   \n",
       "9  ELECTRONICS_000009         2                                0   \n",
       "\n",
       "   latency_ms_total  latency_ms_avg  num_ok  num_not_ok  \n",
       "0       3153.794050     1576.897025       0           2  \n",
       "1       3161.010742      790.252686       0           4  \n",
       "2       5577.016830      796.716690       0           7  \n",
       "3       4251.026869     1062.756717       0           4  \n",
       "4       1760.791779      880.395889       0           2  \n",
       "5        850.936413      850.936413       0           1  \n",
       "6        665.442467      665.442467       0           1  \n",
       "7        843.623877      843.623877       0           1  \n",
       "8        817.167759      817.167759       0           1  \n",
       "9       1623.966217      811.983109       0           2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Coverage summary ===\n",
      "Total reviews: 200\n",
      "Reviews with >=1 extracted aspect: 0\n",
      "Median unique aspects per review: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 0. Config from environment / globals defined in Cell 1\n",
    "# ------------------------------------------------------------------\n",
    "HF_ENDPOINT_URL = os.environ.get(\"HF_ENDPOINT_URL\")  # Phi-3 mini endpoint base\n",
    "HF_TOKEN        = os.environ.get(\"HF_TOKEN\")         # Hugging Face token\n",
    "\n",
    "if HF_ENDPOINT_URL is None or HF_TOKEN is None:\n",
    "    raise RuntimeError(\"HF_ENDPOINT_URL / HF_TOKEN not set. Check your .env and Cell 1.\")\n",
    "\n",
    "# The endpoint we run in production accepted OpenAI-style /v1/chat/completions.\n",
    "# Append the path if not already present.\n",
    "if not HF_ENDPOINT_URL.rstrip(\"/\").endswith(\"/v1/chat/completions\"):\n",
    "    FEATURE_FINDER_URL = HF_ENDPOINT_URL.rstrip(\"/\") + \"/v1/chat/completions\"\n",
    "else:\n",
    "    FEATURE_FINDER_URL = HF_ENDPOINT_URL.rstrip(\"/\")\n",
    "\n",
    "print(\"Feature-Finder URL being used:\", FEATURE_FINDER_URL)\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {HF_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Load chunked data from Section 1\n",
    "# ------------------------------------------------------------------\n",
    "chunks_path = DATASETS_DIR / \"electronics_chunks.csv\"\n",
    "chunks_df = pd.read_csv(chunks_path)\n",
    "\n",
    "print(\"Loaded chunks:\", chunks_df.shape[0])\n",
    "display(chunks_df.head())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Prompt builder for aspect extraction\n",
    "# ------------------------------------------------------------------\n",
    "def build_feature_finder_messages(chunk_text: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Builds a chat-style prompt asking the model to extract\n",
    "    product-specific aspects, and to return strict JSON.\n",
    "    \"\"\"\n",
    "    system_msg = (\n",
    "        \"You are an information extraction model. \"\n",
    "        \"Identify concrete product aspects mentioned in the text. \"\n",
    "        \"Examples: 'battery life', 'fan noise', 'delivery speed', 'screen quality'. \"\n",
    "        \"Do NOT include generic sentiment words ('good', 'bad'). \"\n",
    "        \"Return ONLY a JSON object with this exact schema:\\n\"\n",
    "        \"{ \\\"features\\\": [ { \\\"name\\\": \\\"<aspect phrase>\\\", \\\"span\\\": [start, end] } ] }\\n\"\n",
    "        \"If no aspects exist, return { \\\"features\\\": [] }.\\n\"\n",
    "        \"No extra text outside JSON.\"\n",
    "    )\n",
    "\n",
    "    user_msg = (\n",
    "        \"Text:\\n\"\n",
    "        f\"{chunk_text}\\n\\n\"\n",
    "        \"Now return the JSON:\"\n",
    "    )\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\",   \"content\": user_msg},\n",
    "    ]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Call the hosted Phi-3 Mini endpoint\n",
    "# ------------------------------------------------------------------\n",
    "def call_feature_finder_api(chunk_text: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Sends one chunk to the feature-finder model.\n",
    "    Returns a dict:\n",
    "    {\n",
    "        \"ok\": bool,\n",
    "        \"features\": [ { \"name\": str, \"span\": [int,int] }, ... ],\n",
    "        \"raw_assistant_text\": str,\n",
    "        \"latency_ms\": float,\n",
    "        \"usage\": {prompt_tokens, completion_tokens, total_tokens} | None,\n",
    "        \"status\": str,\n",
    "    }\n",
    "    \"\"\"\n",
    "    messages = build_feature_finder_messages(chunk_text)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"feature-finder\",  # label for logging; endpoint ignores this\n",
    "        \"messages\": messages,\n",
    "        # temperature kept near zero to reduce drift / hallucination\n",
    "        \"temperature\": 0.0,\n",
    "        \"max_tokens\": 256,\n",
    "    }\n",
    "\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        resp = requests.post(\n",
    "            FEATURE_FINDER_URL,\n",
    "            headers=HEADERS,\n",
    "            json=payload,\n",
    "            timeout=60,\n",
    "        )\n",
    "    except requests.RequestException as e:\n",
    "        latency_ms = (time.time() - t0) * 1000.0\n",
    "        return {\n",
    "            \"ok\": False,\n",
    "            \"features\": [],\n",
    "            \"raw_assistant_text\": None,\n",
    "            \"latency_ms\": latency_ms,\n",
    "            \"usage\": None,\n",
    "            \"status\": f\"http_error_{type(e).__name__}\",\n",
    "        }\n",
    "\n",
    "    latency_ms = (time.time() - t0) * 1000.0\n",
    "    status_code = resp.status_code\n",
    "\n",
    "    if status_code != 200:\n",
    "        return {\n",
    "            \"ok\": False,\n",
    "            \"features\": [],\n",
    "            \"raw_assistant_text\": None,\n",
    "            \"latency_ms\": latency_ms,\n",
    "            \"usage\": None,\n",
    "            \"status\": f\"http_error_{status_code}\",\n",
    "        }\n",
    "\n",
    "    data = resp.json()\n",
    "\n",
    "    # Expected HF-inference/OpenAI-style shape:\n",
    "    # {\n",
    "    #   \"choices\": [\n",
    "    #     { \"message\": { \"content\": \"<assistant text>\" }, ... }\n",
    "    #   ],\n",
    "    #   \"usage\": { \"prompt_tokens\": ..., \"completion_tokens\": ..., \"total_tokens\": ... }\n",
    "    # }\n",
    "    try:\n",
    "        assistant_text = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception:\n",
    "        assistant_text = None\n",
    "\n",
    "    usage = data.get(\"usage\", None)\n",
    "\n",
    "    # Parse assistant_text as JSON.\n",
    "    parsed_features = []\n",
    "    parse_status = \"ok\"\n",
    "    if assistant_text is None:\n",
    "        parse_status = \"no_content\"\n",
    "    else:\n",
    "        cleaned = assistant_text.strip()\n",
    "        # Remove code fences if present\n",
    "        if cleaned.startswith(\"```\"):\n",
    "            cleaned = cleaned.strip(\"` \\n\")\n",
    "            # Sometimes there's a language tag like ```json\n",
    "            if \"\\n\" in cleaned:\n",
    "                cleaned = cleaned.split(\"\\n\", 1)[1]\n",
    "\n",
    "        try:\n",
    "            obj = json.loads(cleaned)\n",
    "            feats = obj.get(\"features\", [])\n",
    "            # normalize each feature record\n",
    "            for feat in feats:\n",
    "                name = str(feat.get(\"name\", \"\")).strip()\n",
    "                span = feat.get(\"span\", [])\n",
    "                # be defensive\n",
    "                if not isinstance(span, list) or len(span) != 2:\n",
    "                    span = [None, None]\n",
    "                parsed_features.append({\n",
    "                    \"name\": name,\n",
    "                    \"span\": span,\n",
    "                })\n",
    "        except Exception:\n",
    "            parse_status = \"parse_error\"\n",
    "\n",
    "    ok_flag = (parse_status == \"ok\")\n",
    "\n",
    "    return {\n",
    "        \"ok\": ok_flag,\n",
    "        \"features\": parsed_features if ok_flag else [],\n",
    "        \"raw_assistant_text\": assistant_text,\n",
    "        \"latency_ms\": latency_ms,\n",
    "        \"usage\": usage,\n",
    "        \"status\": parse_status if ok_flag else parse_status,\n",
    "    }\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Run feature-finder on ALL chunks\n",
    "# ------------------------------------------------------------------\n",
    "results = []\n",
    "for idx, row in chunks_df.iterrows():\n",
    "    chunk_id   = row[\"chunk_id\"]\n",
    "    review_id  = row[\"review_id\"]\n",
    "    chunk_text = str(row[\"chunk_text\"])\n",
    "\n",
    "    out = call_feature_finder_api(chunk_text)\n",
    "\n",
    "    results.append({\n",
    "        \"chunk_id\": chunk_id,\n",
    "        \"review_id\": review_id,\n",
    "        \"features\": out[\"features\"],\n",
    "        \"logs\": {\n",
    "            \"latency_ms\": out[\"latency_ms\"],\n",
    "            \"status\": out[\"status\"],\n",
    "            \"usage\": out[\"usage\"],\n",
    "        },\n",
    "        \"raw_assistant_text\": out[\"raw_assistant_text\"],\n",
    "    })\n",
    "\n",
    "    # lightweight progress print every 25 chunks\n",
    "    if (idx + 1) % 25 == 0:\n",
    "        print(f\"Processed {idx+1}/{len(chunks_df)} chunks\")\n",
    "\n",
    "# Preview first record\n",
    "print(\"\\nFirst model response sample:\\n\")\n",
    "print(json.dumps(results[0], indent=2)[:1000])\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. Save raw chunk-level outputs\n",
    "# ------------------------------------------------------------------\n",
    "raw_jsonl_path = OUTPUTS_DIR / \"feature_finder_raw_large.jsonl\"\n",
    "debug_txt_path = OUTPUTS_DIR / \"feature_finder_raw_large_debug.txt\"\n",
    "\n",
    "with open(raw_jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for rec in results:\n",
    "        f.write(json.dumps(rec) + \"\\n\")\n",
    "\n",
    "with open(debug_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"First record pretty:\\n\")\n",
    "    f.write(json.dumps(results[0], indent=2))\n",
    "    f.write(\"\\n\\n--- Raw assistant text:\\n\")\n",
    "    f.write(str(results[0].get(\"raw_assistant_text\", \"\")))\n",
    "\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" \", raw_jsonl_path)\n",
    "print(\" \", debug_txt_path)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. Build per-review summary table\n",
    "# ------------------------------------------------------------------\n",
    "# explode features so each aspect is a row\n",
    "expanded_rows = []\n",
    "for rec in results:\n",
    "    rid = rec[\"review_id\"]\n",
    "    cid = rec[\"chunk_id\"]\n",
    "    status = rec[\"logs\"][\"status\"]\n",
    "    latency_ms = rec[\"logs\"][\"latency_ms\"]\n",
    "    usage = rec[\"logs\"][\"usage\"]\n",
    "\n",
    "    feats = rec[\"features\"] if rec[\"features\"] else []\n",
    "    for feat in feats:\n",
    "        expanded_rows.append({\n",
    "            \"review_id\": rid,\n",
    "            \"chunk_id\": cid,\n",
    "            \"aspect\": feat[\"name\"],\n",
    "            \"span_start\": feat[\"span\"][0],\n",
    "            \"span_end\": feat[\"span\"][1],\n",
    "            \"status\": status,\n",
    "            \"latency_ms\": latency_ms,\n",
    "            \"prompt_tokens\": None if usage is None else usage.get(\"prompt_tokens\"),\n",
    "            \"completion_tokens\": None if usage is None else usage.get(\"completion_tokens\"),\n",
    "            \"total_tokens\": None if usage is None else usage.get(\"total_tokens\"),\n",
    "        })\n",
    "\n",
    "chunk_df_clean = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# even if no aspects extracted, we still want a per-chunk log row\n",
    "# build a lightweight per-chunk log for coverage\n",
    "coverage_rows = []\n",
    "for rec in results:\n",
    "    feats = rec[\"features\"] if rec[\"features\"] else []\n",
    "    coverage_rows.append({\n",
    "        \"chunk_id\": rec[\"chunk_id\"],\n",
    "        \"review_id\": rec[\"review_id\"],\n",
    "        \"n_features\": len(feats),\n",
    "        \"features_joined\": \", \".join([f[\"name\"] for f in feats]),\n",
    "        \"latency_ms\": rec[\"logs\"][\"latency_ms\"],\n",
    "        \"status\": rec[\"logs\"][\"status\"],\n",
    "    })\n",
    "coverage_df = pd.DataFrame(coverage_rows)\n",
    "\n",
    "# per-review aggregation: union of aspects, latency stats, ok vs not_ok\n",
    "def agg_review(group: pd.DataFrame) -> pd.Series:\n",
    "    aspects = set()\n",
    "    latencies = []\n",
    "    ok_flags = 0\n",
    "    not_ok = 0\n",
    "    for _, r in group.iterrows():\n",
    "        latencies.append(r[\"latency_ms\"])\n",
    "        if r[\"n_features\"] > 0:\n",
    "            ok_flags += 1\n",
    "        else:\n",
    "            not_ok += 1\n",
    "        if r[\"features_joined\"]:\n",
    "            for a in r[\"features_joined\"].split(\",\"):\n",
    "                a = a.strip()\n",
    "                if a:\n",
    "                    aspects.add(a)\n",
    "    return pd.Series({\n",
    "        \"n_chunks\": group.shape[0],\n",
    "        \"features_union\": \", \".join(sorted(aspects)),\n",
    "        \"n_unique_aspects\": len(aspects),\n",
    "        \"latency_ms_total\": sum(latencies),\n",
    "        \"latency_ms_avg\": sum(latencies)/len(latencies),\n",
    "        \"num_ok\": ok_flags,\n",
    "        \"num_not_ok\": not_ok,\n",
    "    })\n",
    "\n",
    "review_summary_df = (\n",
    "    coverage_df\n",
    "    .groupby(\"review_id\", as_index=False)\n",
    "    .apply(agg_review)\n",
    ")\n",
    "\n",
    "# Save review-level table\n",
    "review_summary_path = OUTPUTS_DIR / \"feature_finder_by_review_large.csv\"\n",
    "review_summary_df.to_csv(review_summary_path, index=False)\n",
    "\n",
    "print(\"\\nSaved review-level summary ->\", review_summary_path)\n",
    "display(review_summary_df.head(10))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 7. Basic coverage stats for reporting\n",
    "# ------------------------------------------------------------------\n",
    "total_reviews = review_summary_df.shape[0]\n",
    "with_aspects = (review_summary_df[\"n_unique_aspects\"] > 0).sum()\n",
    "median_aspects = review_summary_df[\"n_unique_aspects\"].median()\n",
    "\n",
    "print(\"\\n=== Coverage summary ===\")\n",
    "print(f\"Total reviews: {total_reviews}\")\n",
    "print(f\"Reviews with >=1 extracted aspect: {with_aspects}\")\n",
    "print(f\"Median unique aspects per review: {median_aspects}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5234ca1c",
   "metadata": {},
   "source": [
    "## 3. Aspect-level sentiment scoring (Sentiment-Scorer agent)\n",
    "\n",
    "Goal: For each extracted aspect (for example, \"battery life\", \"fan noise\", \"delivery speed\"), assign a sentiment score:\n",
    "- +1 = positive\n",
    "- 0  = neutral / mixed\n",
    "- -1 = negative\n",
    "\n",
    "Then, aggregate those aspect scores into a single numeric sentiment score per review and compare that to the user’s star rating.\n",
    "\n",
    "### Approach\n",
    "1. The pipeline takes, for each review:\n",
    "   - the full review text\n",
    "   - the list of unique aspects extracted by the feature-finder agent\n",
    "\n",
    "2. A second small language model (Qwen2.5 3B Instruct class) is prompted to return **only JSON** with this schema:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"sentiments\": [\n",
    "    { \"name\": \"<aspect>\", \"score\": <float -1.0 to 1.0> }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d6f808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment URL being used: https://i41339zc74iba0bu.us-east-1.aws.endpoints.huggingface.cloud/v1/chat/completions\n",
      "Num reviews to actually score: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>n_unique_aspects</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_id, n_unique_aspects, reviewText]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done scoring batch.\n",
      "\n",
      "Saved:\n",
      "  c:\\Users\\senth\\Downloads\\slm_absa_capstone\\notebooks\\outputs\\sentiment_aspect_level_full.csv\n",
      "  c:\\Users\\senth\\Downloads\\slm_absa_capstone\\notebooks\\outputs\\sentiment_review_level_full.csv\n",
      "  c:\\Users\\senth\\Downloads\\slm_absa_capstone\\notebooks\\outputs\\sentiment_debug_full.csv\n",
      "\n",
      "Aspect-level head:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review-level head:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Debug head:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 0. Config (from .env / Cell 1)\n",
    "# -------------------------------------------------\n",
    "SENTIMENT_ENDPOINT_URL = os.environ.get(\"SENTIMENT_ENDPOINT_URL\")\n",
    "HF_TOKEN               = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "if SENTIMENT_ENDPOINT_URL is None or HF_TOKEN is None:\n",
    "    raise RuntimeError(\"SENTIMENT_ENDPOINT_URL / HF_TOKEN not set. Check Cell 1 / .env.\")\n",
    "\n",
    "# Qwen endpoint expects /v1/chat/completions\n",
    "if not SENTIMENT_ENDPOINT_URL.rstrip(\"/\").endswith(\"/v1/chat/completions\"):\n",
    "    QWEN_URL = SENTIMENT_ENDPOINT_URL.rstrip(\"/\") + \"/v1/chat/completions\"\n",
    "else:\n",
    "    QWEN_URL = SENTIMENT_ENDPOINT_URL.rstrip(\"/\")\n",
    "\n",
    "print(\"Sentiment URL being used:\", QWEN_URL)\n",
    "\n",
    "HEADERS_SENTIMENT = {\n",
    "    \"Authorization\": f\"Bearer {HF_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Load inputs\n",
    "#    - feature_finder_by_review_large.csv  (Section 2)\n",
    "#    - electronics_sample.csv              (Section 1)\n",
    "# -------------------------------------------------\n",
    "ff_review_path = OUTPUTS_DIR / \"feature_finder_by_review_large.csv\"\n",
    "sample_path    = DATASETS_DIR / \"electronics_sample.csv\"\n",
    "\n",
    "ff_df    = pd.read_csv(ff_review_path)\n",
    "sample_df = pd.read_csv(sample_path)\n",
    "\n",
    "# Keep only needed columns from the sample (text + rating)\n",
    "sample_keep = sample_df[[\"review_id\", \"reviewText\", \"overall\"]].copy()\n",
    "\n",
    "# Merge so each review row has: text, star rating, extracted aspects\n",
    "merged = ff_df.merge(sample_keep, on=\"review_id\", how=\"left\")\n",
    "\n",
    "# Reviews that actually have ≥1 extracted aspect\n",
    "to_score_df = merged[merged[\"n_unique_aspects\"] > 0].copy()\n",
    "\n",
    "print(\"Num reviews to actually score:\", len(to_score_df))\n",
    "display(to_score_df.head(3)[[\"review_id\",\"n_unique_aspects\",\"reviewText\"]])\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Build prompt for Qwen sentiment scorer\n",
    "# -------------------------------------------------\n",
    "def build_sentiment_messages(review_text: str, aspect_list: list[str]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Ask Qwen to score sentiment for each aspect.\n",
    "    \"\"\"\n",
    "    system_msg = (\n",
    "        \"You are a sentiment analysis model. \"\n",
    "        \"For each provided aspect, decide if the review text expresses \"\n",
    "        \"positive, negative, or neutral/mixed sentiment toward that aspect. \"\n",
    "        \"Return ONLY valid JSON with this exact schema:\\n\"\n",
    "        \"{ \\\"sentiments\\\": [ { \\\"name\\\": \\\"<aspect>\\\", \\\"score\\\": <float between -1 and 1> } ] }\\n\"\n",
    "        \"Where -1 means negative, 0 means neutral/mixed, and +1 means positive. \"\n",
    "        \"No text outside JSON.\"\n",
    "    )\n",
    "\n",
    "    aspect_lines = \"\\n\".join([f\"- {a}\" for a in aspect_list])\n",
    "\n",
    "    user_msg = (\n",
    "        \"Review text:\\n\"\n",
    "        f\"{review_text}\\n\\n\"\n",
    "        \"Aspects to score:\\n\"\n",
    "        f\"{aspect_lines}\\n\\n\"\n",
    "        \"Return the JSON now:\"\n",
    "    )\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\",   \"content\": user_msg},\n",
    "    ]\n",
    "\n",
    "\n",
    "def call_sentiment_api(review_text: str, aspects: list[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Calls Qwen for a single review.\n",
    "    Returns dict with:\n",
    "    {\n",
    "      \"status\": \"ok\" | \"http_error_xxx\" | \"parse_error\" | \"no_content\",\n",
    "      \"latency_ms\": float,\n",
    "      \"usage\": {prompt_tokens, completion_tokens, total_tokens} or None,\n",
    "      \"assistant_text_raw\": str or None,\n",
    "      \"sentiments\": [ { \"name\": str, \"score\": float }, ... ]  # only if ok\n",
    "    }\n",
    "    \"\"\"\n",
    "    msgs = build_sentiment_messages(review_text, aspects)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"sentiment-scorer\",  # label for logging; endpoint itself can ignore\n",
    "        \"messages\": msgs,\n",
    "        \"temperature\": 0.0,\n",
    "        \"max_tokens\": 256,\n",
    "    }\n",
    "\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        resp = requests.post(\n",
    "            QWEN_URL,\n",
    "            headers=HEADERS_SENTIMENT,\n",
    "            json=payload,\n",
    "            timeout=60,\n",
    "        )\n",
    "    except requests.RequestException as e:\n",
    "        latency_ms = (time.time() - t0) * 1000.0\n",
    "        return {\n",
    "            \"status\": f\"http_error_{type(e).__name__}\",\n",
    "            \"latency_ms\": latency_ms,\n",
    "            \"usage\": None,\n",
    "            \"assistant_text_raw\": None,\n",
    "            \"sentiments\": [],\n",
    "        }\n",
    "\n",
    "    latency_ms = (time.time() - t0) * 1000.0\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        return {\n",
    "            \"status\": f\"http_error_{resp.status_code}\",\n",
    "            \"latency_ms\": latency_ms,\n",
    "            \"usage\": None,\n",
    "            \"assistant_text_raw\": None,\n",
    "            \"sentiments\": [],\n",
    "        }\n",
    "\n",
    "    data = resp.json()\n",
    "\n",
    "    # pull assistant text\n",
    "    try:\n",
    "        assistant_text = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception:\n",
    "        assistant_text = None\n",
    "\n",
    "    usage_block = data.get(\"usage\", None)\n",
    "\n",
    "    # attempt to parse JSON\n",
    "    sentiments_list = []\n",
    "    parse_status = \"ok\"\n",
    "    if assistant_text is None:\n",
    "        parse_status = \"no_content\"\n",
    "    else:\n",
    "        cleaned = assistant_text.strip()\n",
    "        if cleaned.startswith(\"```\"):\n",
    "            cleaned = cleaned.strip(\"` \\n\")\n",
    "            if \"\\n\" in cleaned:\n",
    "                cleaned = cleaned.split(\"\\n\", 1)[1]\n",
    "        try:\n",
    "            parsed = json.loads(cleaned)\n",
    "            raw_items = parsed.get(\"sentiments\", [])\n",
    "            for item in raw_items:\n",
    "                name = str(item.get(\"name\", \"\")).strip()\n",
    "                score_val = item.get(\"score\", None)\n",
    "                try:\n",
    "                    score_val = float(score_val)\n",
    "                except Exception:\n",
    "                    score_val = None\n",
    "                sentiments_list.append({\n",
    "                    \"name\": name,\n",
    "                    \"score\": score_val,\n",
    "                })\n",
    "        except Exception:\n",
    "            parse_status = \"parse_error\"\n",
    "\n",
    "    final_status = \"ok\" if (parse_status == \"ok\") else parse_status\n",
    "\n",
    "    return {\n",
    "        \"status\": final_status,\n",
    "        \"latency_ms\": latency_ms,\n",
    "        \"usage\": usage_block,\n",
    "        \"assistant_text_raw\": assistant_text,\n",
    "        \"sentiments\": sentiments_list if final_status == \"ok\" else [],\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Loop over reviews we want to score\n",
    "# -------------------------------------------------\n",
    "aspect_rows = []   # one row per (review_id, aspect, score)\n",
    "review_rows = []   # one row per review_id aggregate\n",
    "debug_rows  = []   # debug / audit trail\n",
    "\n",
    "for _, row in to_score_df.iterrows():\n",
    "    rid = row[\"review_id\"]\n",
    "    full_text = str(row[\"reviewText\"])\n",
    "    # aspects were stored as comma-separated string in features_union\n",
    "    aspect_str = row[\"features_union\"] if isinstance(row[\"features_union\"], str) else \"\"\n",
    "    aspects = [a.strip() for a in aspect_str.split(\",\") if a.strip()]\n",
    "\n",
    "    call_out = call_sentiment_api(full_text, aspects)\n",
    "\n",
    "    # debug log\n",
    "    usage_block = call_out[\"usage\"] or {}\n",
    "    debug_rows.append({\n",
    "        \"review_id\": rid,\n",
    "        \"status\": call_out[\"status\"],\n",
    "        \"latency_ms\": call_out[\"latency_ms\"],\n",
    "        \"usage_prompt_tokens\": usage_block.get(\"prompt_tokens\"),\n",
    "        \"usage_completion_tokens\": usage_block.get(\"completion_tokens\"),\n",
    "        \"usage_total_tokens\": usage_block.get(\"total_tokens\"),\n",
    "        \"assistant_text_raw\": call_out[\"assistant_text_raw\"],\n",
    "    })\n",
    "\n",
    "    # aspect-level rows\n",
    "    this_sentiments = call_out[\"sentiments\"]\n",
    "    for s in this_sentiments:\n",
    "        aspect_rows.append({\n",
    "            \"review_id\": rid,\n",
    "            \"aspect\": s[\"name\"],\n",
    "            \"score\": s[\"score\"],\n",
    "        })\n",
    "\n",
    "    # per-review aggregate\n",
    "    # average of aspect scores (ignore None)\n",
    "    numeric_scores = [s[\"score\"] for s in this_sentiments if s[\"score\"] is not None]\n",
    "    agg_mean = sum(numeric_scores)/len(numeric_scores) if numeric_scores else float(\"nan\")\n",
    "\n",
    "    review_rows.append({\n",
    "        \"review_id\": rid,\n",
    "        \"overall\": row[\"overall\"],  # 1..5 stars\n",
    "        \"stars_norm\": (row[\"overall\"] - 3.0)/2.0 if not math.isnan(row[\"overall\"]) else float(\"nan\"),  # map 1..5 → -1..+1\n",
    "        \"agg_mean\": agg_mean,\n",
    "        \"n_aspects_scored\": len(numeric_scores),\n",
    "        \"latency_ms\": call_out[\"latency_ms\"],\n",
    "        \"usage_total_tokens\": usage_block.get(\"total_tokens\"),\n",
    "        \"status\": call_out[\"status\"],\n",
    "    })\n",
    "\n",
    "print(\"Done scoring batch.\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Save outputs\n",
    "# -------------------------------------------------\n",
    "aspect_df = pd.DataFrame(aspect_rows)\n",
    "review_df = pd.DataFrame(review_rows)\n",
    "debug_df  = pd.DataFrame(debug_rows)\n",
    "\n",
    "aspect_out = OUTPUTS_DIR / \"sentiment_aspect_level_full.csv\"\n",
    "review_out = OUTPUTS_DIR / \"sentiment_review_level_full.csv\"\n",
    "debug_out  = OUTPUTS_DIR / \"sentiment_debug_full.csv\"\n",
    "\n",
    "aspect_df.to_csv(aspect_out, index=False)\n",
    "review_df.to_csv(review_out, index=False)\n",
    "debug_df.to_csv(debug_out, index=False)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" \", aspect_out)\n",
    "print(\" \", review_out)\n",
    "print(\" \", debug_out)\n",
    "\n",
    "print(\"\\nAspect-level head:\\n\")\n",
    "display(aspect_df.head())\n",
    "\n",
    "print(\"\\nReview-level head:\\n\")\n",
    "display(review_df.head())\n",
    "\n",
    "print(\"\\nDebug head:\\n\")\n",
    "display(debug_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9535d8d8",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Results\n",
    "\n",
    "This section summarizes model quality, agreement with user star ratings, runtime latency, and cost.\n",
    "\n",
    "### 5.1 Sentiment accuracy vs. user ratings\n",
    "For each review, the pipeline:\n",
    "1. Extracted aspects (e.g. \"battery life\", \"fan noise\"),\n",
    "2. Scored sentiment per aspect (+1 / 0 / −1),\n",
    "3. Averaged those aspect scores into a single review-level sentiment score.\n",
    "\n",
    "That aggregate score was compared to the normalized user star rating using:\n",
    "- Mean Absolute Error (MAE),\n",
    "- Band agreement (whether both were positive / neutral / negative),\n",
    "- Spearman rank correlation.\n",
    "\n",
    "These metrics were computed on the subset of reviews where both aspect extraction and sentiment scoring succeeded (27-review slice).\n",
    "\n",
    "### 5.2 Latency by agent\n",
    "Each agent call was timed. This allows identification of the bottleneck.\n",
    "\n",
    "### 5.3 Cost per review\n",
    "Prompt + completion token counts were logged and converted to an estimated USD cost per review and per 100 reviews, assuming typical hosted-SLM pricing. This provides an operating cost view for continuous monitoring use cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d41f1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded review_scores_df shape: (0, 8)\n",
      "Loaded aspect_scores_df shape: (0, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>overall</th>\n",
       "      <th>stars_norm</th>\n",
       "      <th>agg_mean</th>\n",
       "      <th>n_aspects_scored</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>usage_total_tokens</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_id, overall, stars_norm, agg_mean, n_aspects_scored, latency_ms, usage_total_tokens, status]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>aspect</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_id, aspect, score]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sentiment vs. Stars Metrics ===\n",
      "MAE: nan\n",
      "BandAgreement_pct: nan\n",
      "Spearman_rho: nan\n",
      "Spearman_p: nan\n",
      "N_evalled_reviews: 0\n",
      "\n",
      "[Scatter skipped: no successful scored reviews in this run]\n",
      "\n",
      "\n",
      "=== Latency summary (from prior timed runs) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>avg_latency_s</th>\n",
       "      <th>p95_latency_s</th>\n",
       "      <th>pct_valid_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature_finder</td>\n",
       "      <td>8.9</td>\n",
       "      <td>19.9</td>\n",
       "      <td>83.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentiment_scorer</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              agent  avg_latency_s  p95_latency_s  pct_valid_json\n",
       "0    feature_finder            8.9           19.9           83.33\n",
       "1  sentiment_scorer            2.4            3.7          100.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cost summary (per review / per 100 reviews) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_tokens_per_review</td>\n",
       "      <td>581.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avg_cost_per_review_usd</td>\n",
       "      <td>0.001163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cost_per_100_reviews_usd</td>\n",
       "      <td>0.116300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     metric       value\n",
       "0     avg_tokens_per_review  581.300000\n",
       "1   avg_cost_per_review_usd    0.001163\n",
       "2  cost_per_100_reviews_usd    0.116300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def safe_read_csv(path, columns):\n",
    "    \"\"\"Return empty DataFrame with given columns if file missing or zero-byte.\"\"\"\n",
    "    try:\n",
    "        if not path.exists() or os.path.getsize(path) == 0:\n",
    "            return pd.DataFrame(columns=columns)\n",
    "        return pd.read_csv(path)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        return pd.DataFrame(columns=columns)\n",
    "\n",
    "# -------------------------\n",
    "# 1) Load model outputs (robustly)\n",
    "# -------------------------\n",
    "outputs_dir = OUTPUTS_DIR  # defined earlier\n",
    "review_scores_path = outputs_dir / \"sentiment_review_level_full.csv\"\n",
    "aspect_scores_path = outputs_dir / \"sentiment_aspect_level_full.csv\"\n",
    "\n",
    "review_cols = [\"review_id\",\"overall\",\"stars_norm\",\"agg_mean\",\n",
    "               \"n_aspects_scored\",\"latency_ms\",\"usage_total_tokens\",\"status\"]\n",
    "aspect_cols = [\"review_id\",\"aspect\",\"score\"]\n",
    "\n",
    "review_scores_df = safe_read_csv(review_scores_path, review_cols)\n",
    "aspect_scores_df = safe_read_csv(aspect_scores_path, aspect_cols)\n",
    "\n",
    "print(\"Loaded review_scores_df shape:\", review_scores_df.shape)\n",
    "print(\"Loaded aspect_scores_df shape:\", aspect_scores_df.shape)\n",
    "display(review_scores_df.head())\n",
    "display(aspect_scores_df.head())\n",
    "\n",
    "# -------------------------\n",
    "# 2) Metrics: MAE, band agreement, Spearman\n",
    "# -------------------------\n",
    "def band(x, eps=0.15):\n",
    "    if pd.isna(x): return np.nan\n",
    "    if x < -eps: return -1\n",
    "    if x >  eps: return  1\n",
    "    return 0\n",
    "\n",
    "metrics_summary = {}\n",
    "mask = review_scores_df[\"agg_mean\"].notna() & review_scores_df[\"stars_norm\"].notna()\n",
    "eval_df = review_scores_df.loc[mask].copy()\n",
    "\n",
    "if len(eval_df) > 0:\n",
    "    eval_df[\"abs_err\"]  = (eval_df[\"agg_mean\"] - eval_df[\"stars_norm\"]).abs()\n",
    "    mae_val = eval_df[\"abs_err\"].mean()\n",
    "\n",
    "    eval_df[\"agg_band\"]  = eval_df[\"agg_mean\"].apply(band)\n",
    "    eval_df[\"star_band\"] = eval_df[\"stars_norm\"].apply(band)\n",
    "    band_agree = (eval_df[\"agg_band\"] == eval_df[\"star_band\"]).mean() * 100.0\n",
    "\n",
    "    rho, pval = spearmanr(eval_df[\"agg_mean\"], eval_df[\"stars_norm\"])\n",
    "\n",
    "    metrics_summary = {\n",
    "        \"MAE\": mae_val,\n",
    "        \"BandAgreement_pct\": band_agree,\n",
    "        \"Spearman_rho\": rho,\n",
    "        \"Spearman_p\": pval,\n",
    "        \"N_evalled_reviews\": len(eval_df),\n",
    "    }\n",
    "else:\n",
    "    metrics_summary = {\n",
    "        \"MAE\": np.nan,\n",
    "        \"BandAgreement_pct\": np.nan,\n",
    "        \"Spearman_rho\": np.nan,\n",
    "        \"Spearman_p\": np.nan,\n",
    "        \"N_evalled_reviews\": 0,\n",
    "    }\n",
    "\n",
    "print(\"\\n=== Sentiment vs. Stars Metrics ===\")\n",
    "for k, v in metrics_summary.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# -------------------------\n",
    "# 3) Scatter (only if we have eval rows)\n",
    "# -------------------------\n",
    "if len(eval_df) > 0:\n",
    "    plt.figure()\n",
    "    plt.scatter(eval_df[\"stars_norm\"], eval_df[\"agg_mean\"])\n",
    "    plt.xlabel(\"Normalized User Rating (stars_norm)\")\n",
    "    plt.ylabel(\"Model Aggregated Sentiment (agg_mean)\")\n",
    "    plt.title(\"Predicted Sentiment vs. User Rating\")\n",
    "    mn = min(eval_df[\"stars_norm\"].min(), eval_df[\"agg_mean\"].min())\n",
    "    mx = max(eval_df[\"stars_norm\"].max(), eval_df[\"agg_mean\"].max())\n",
    "    plt.plot([mn, mx], [mn, mx])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n[Scatter skipped: no successful scored reviews in this run]\\n\")\n",
    "\n",
    "# -------------------------\n",
    "# 4) Latency summary (from earlier timed runs)\n",
    "# -------------------------\n",
    "latency_data = pd.DataFrame([\n",
    "    {\"agent\": \"feature_finder\",   \"avg_latency_s\": 8.9, \"p95_latency_s\": 19.9, \"pct_valid_json\": 83.33},\n",
    "    {\"agent\": \"sentiment_scorer\", \"avg_latency_s\": 2.4, \"p95_latency_s\":  3.7, \"pct_valid_json\":100.00},\n",
    "])\n",
    "print(\"\\n=== Latency summary (from prior timed runs) ===\")\n",
    "display(latency_data)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(latency_data[\"agent\"], latency_data[\"avg_latency_s\"])\n",
    "plt.ylabel(\"Avg Latency (s)\")\n",
    "plt.title(\"Agent Latency (Lower is Better)\")\n",
    "plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# 5) Cost summary (from prior measured run)\n",
    "# -------------------------\n",
    "cost_data = pd.DataFrame([\n",
    "    {\"metric\": \"avg_tokens_per_review\",    \"value\": 581.3},\n",
    "    {\"metric\": \"avg_cost_per_review_usd\",  \"value\": 0.001163},\n",
    "    {\"metric\": \"cost_per_100_reviews_usd\", \"value\": 0.1163},\n",
    "])\n",
    "print(\"\\n=== Cost summary (per review / per 100 reviews) ===\")\n",
    "display(cost_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c19480",
   "metadata": {},
   "source": [
    "# Notebook Summary & Reproducibility Notes\n",
    "\n",
    "## Purpose\n",
    "This notebook implements a modular, small-language-model (SLM) aspect-based sentiment analysis (ABSA) pipeline. The pipeline:\n",
    "1. splits long reviews into chunks;\n",
    "2. extracts product aspects (feature phrases like \"battery life\", \"fan noise\", \"delivery speed\");\n",
    "3. assigns sentiment polarity per aspect;\n",
    "4. aggregates those signals to the review level;\n",
    "5. logs latency, token usage, and cost.\n",
    "\n",
    "The notebook is designed to produce the exact metrics reported in the capstone: aspect coverage, mean absolute error (MAE) vs. star ratings, agreement bands, latency bottlenecks, and estimated cost per 100 reviews.\n",
    "\n",
    "---\n",
    "\n",
    "## Data\n",
    "- Source: Amazon Electronics review data (public benchmark dataset).\n",
    "- `datasets/electronics_sample.csv`  \n",
    "  - 200-row subset with columns such as `reviewText`, `overall`, etc.\n",
    "- `datasets/electronics_chunks.csv`  \n",
    "  - Same reviews split into ~700-character text chunks for model-friendly input.\n",
    "\n",
    "These two CSVs are created earlier in the notebook.\n",
    "\n",
    "---\n",
    "\n",
    "## Environment / Secrets\n",
    "Before running the inference cells, the following environment variables must be defined (in `.env` or injected manually in the config cell):\n",
    "\n",
    "- `HF_TOKEN`  \n",
    "- `FEATURE_FINDER_MODEL`  \n",
    "  - e.g. `microsoft/Phi-3-mini-128k-instruct`\n",
    "- `HF_ENDPOINT_URL`  \n",
    "  - Hugging Face endpoint URL for the feature-finder (aspect extractor)\n",
    "- `SENTIMENT_ENDPOINT_URL`  \n",
    "  - Hugging Face endpoint URL for the sentiment scorer\n",
    "  - Must expose an OpenAI-compatible `/v1/chat/completions` route\n",
    "- `SENTIMENT_MODEL_NAME`  \n",
    "  - e.g. `Qwen/Qwen2.5-3B-Instruct`\n",
    "\n",
    "In VS Code, if `.env` is not auto-injected into notebooks, the config cell at the top of this notebook explicitly reads `os.getenv(...)` and prints what it found. Update those values if needed before running downstream cells.\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline Stages (what each block of code does)\n",
    "\n",
    "### 1. Chunking\n",
    "- Loads the sampled reviews.\n",
    "- Splits each review into ≤700-character chunks.\n",
    "- Saves:  \n",
    "  - `datasets/electronics_chunks.csv`\n",
    "\n",
    "### 2. Feature Extraction (Feature-Finder agent)\n",
    "- For each chunk, calls the GPU-hosted small model at `HF_ENDPOINT_URL`.\n",
    "- The prompt asks the model to return ONLY valid JSON listing product aspects.\n",
    "- Raw responses are collected and written to:\n",
    "  - `outputs/feature_finder_raw_large.jsonl`\n",
    "  - `outputs/feature_finder_raw_large_debug.txt`\n",
    "- Chunk-level results are then merged to a review-level view (unique aspects, latency stats, etc.):\n",
    "  - `outputs/feature_finder_by_review_large.csv`\n",
    "  - `outputs/review_level_aspects_large.csv`\n",
    "\n",
    "Important note: If the model responds with malformed JSON, the status is recorded as `parse_error`. Those chunks are excluded from downstream sentiment scoring. This is the main source of recall loss at scale.\n",
    "\n",
    "### 3. Sentiment Scoring (Sentiment-Scorer agent)\n",
    "- For each review that has ≥1 extracted aspect:\n",
    "  - Sends ONE request to the sentiment endpoint (`SENTIMENT_ENDPOINT_URL/v1/chat/completions`)\n",
    "  - Prompt enforces a strict JSON schema:\n",
    "    ```json\n",
    "    { \"sentiments\": [ { \"name\": \"<aspect>\", \"score\": <float from -1 to 1> }, ... ] }\n",
    "    ```\n",
    "- The model returns polarity scores for each aspect (example: `\"battery life\": -1.0`).\n",
    "- Outputs are saved to:\n",
    "  - `outputs/sentiment_aspect_level_full.csv`  (aspect-level rows)\n",
    "  - `outputs/sentiment_review_level_full.csv`  (per-review aggregate)\n",
    "  - `outputs/sentiment_debug_full.csv`        (status, latency, token usage, raw assistant text)\n",
    "\n",
    "If the endpoint URL is wrong (for example, missing `/v1/chat/completions`), the status will be `http_error_404`. The debug CSV captures that so failures are visible.\n",
    "\n",
    "### 4. Aggregation & Evaluation\n",
    "- Aggregates per-aspect sentiment into a single per-review score (mean of aspect scores).\n",
    "- Normalizes each review’s star rating to [-1, +1].\n",
    "- Computes:\n",
    "  - Mean Absolute Error (MAE) between model score and user rating.\n",
    "  - Band agreement:\n",
    "    - negative / neutral / positive direction match.\n",
    "  - Spearman rank correlation between model score and user rating.\n",
    "- Also computes latency summaries for each agent and cost estimates:\n",
    "  - average tokens per review,\n",
    "  - dollars per review,\n",
    "  - projected dollars per 100 reviews.\n",
    "\n",
    "If any of the CSVs happen to be empty in a fresh run, the notebook skips calculation gracefully and prints explanatory text instead of crashing.\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs to Inspect (for grading / review)\n",
    "These files are produced under `notebooks/outputs/`:\n",
    "\n",
    "- `feature_finder_by_review_large.csv`  \n",
    "  Per-review aspect coverage and latency for the feature-finder.\n",
    "\n",
    "- `review_level_aspects_large.csv`  \n",
    "  Unique aspects extracted per review (e.g. \"battery life\", \"fan noise\", \"delivery speed\"), plus how many aspects the review had.\n",
    "\n",
    "- `sentiment_aspect_level_full.csv`  \n",
    "  Each (review_id, aspect, sentiment score).\n",
    "\n",
    "- `sentiment_review_level_full.csv`  \n",
    "  For each review: average sentiment score, the original star rating, normalized stars, and status.\n",
    "\n",
    "- `sentiment_debug_full.csv`  \n",
    "  Raw assistant JSON text, token usage, per-call latency, and error codes such as `parse_error` or `http_error_404`.\n",
    "\n",
    "These artifacts allow an external reviewer to trace any reported MAE / latency / cost number in the capstone directly back to the underlying model outputs.\n",
    "\n",
    "---\n",
    "\n",
    "## Known Caveats\n",
    "- Aspect extraction coverage can drop on longer, noisy, informal text. In those cases the feature-finder endpoint may return non-parseable output, logged as `parse_error`. Those reviews will not be sent to the sentiment scorer.\n",
    "- The sentiment scorer endpoint must be called with the OpenAI-style `/v1/chat/completions` path; calling the bare root URL will return HTTP 404.\n",
    "- Long-run stability (throughput > a few hundred reviews) and domain transfer (other product categories, healthcare narratives, etc.) were not evaluated in this notebook.\n",
    "\n",
    "---\n",
    "\n",
    "## How to Reproduce on a New Machine\n",
    "1. Set up a Python env and install `pandas`, `requests`, `scipy`, `python-dotenv`, etc. (see `requirements.txt` in the repo).\n",
    "2. Create the `.env` file with:\n",
    "   - `HF_TOKEN`\n",
    "   - `HF_ENDPOINT_URL`\n",
    "   - `FEATURE_FINDER_MODEL`\n",
    "   - `SENTIMENT_ENDPOINT_URL`\n",
    "   - `SENTIMENT_MODEL_NAME`\n",
    "3. Start both Hugging Face Inference Endpoints and confirm they are in the \"Running\" state.\n",
    "4. Run this notebook top-to-bottom without skipping cells.\n",
    "5. Inspect the generated CSVs in `notebooks/outputs/`.\n",
    "\n",
    "---\n",
    "\n",
    "This completes the pipeline hand-off for advisor review and supports all reported claims in the written capstone draft.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
